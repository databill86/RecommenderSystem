{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_type = 'Amazon', 'InstantVideo'\n",
    "dataset, dataset_type = 'Amazon', 'MoviesTV'\n",
    "\n",
    "dataset_path = './../Datasets/' + dataset + '/' + dataset_type # Full dataset path\n",
    "\n",
    "filename = 'ratings_Movies_and_TV.csv';\n",
    "new_filename = 'ratings.csv'\n",
    "file_path = dataset_path + '_raw/' + filename\n",
    "new_file_path = dataset_path + '/' + new_filename\n",
    "\n",
    "print (\"Old file: \", file_path)\n",
    "print (\"New file: \", new_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_ratings = pd.read_csv(file_path, header = None, names = ['user', 'item', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder_user = LabelEncoder()\n",
    "encoder_item = LabelEncoder()\n",
    "\n",
    "df_ratings[\"user_id\"] = encoder_user.fit_transform(df_ratings[\"user\"])\n",
    "df_ratings[\"item_id\"] = encoder_item.fit_transform(df_ratings[\"item\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding_users = pd.DataFrame(columns=['user', 'user_id'])\n",
    "df_encoding_users['user'] = encoder_user.classes_\n",
    "df_encoding_users['user_id'] = encoder_user.transform(encoder_user.classes_)\n",
    "df_encoding_users.to_csv(dataset_path + '/encoding_users.tsv', header = True, sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoding_items = pd.DataFrame(columns=['item', 'item_id'])\n",
    "df_encoding_items['item'] = encoder_item.classes_\n",
    "df_encoding_items['item_id'] = encoder_item.transform(encoder_item.classes_)\n",
    "df_encoding_items.to_csv(dataset_path + '/encoding_items.tsv', header = True, sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings[['user_id', 'item_id', 'rating', 'timestamp']].to_csv(new_file_path, header = True, sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(encoder_user, dataset_path + '/encoder_user_trained.joblib')\n",
    "joblib.dump(encoder_item, dataset_path + '/encoder_item_trained.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.to_csv(new_file_path, header = True, sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Line by Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"DATA STYLE:\")\n",
    "\n",
    "fin = open(file_path)\n",
    "print (fin.readline())\n",
    "print (fin.readline())\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = ','\n",
    "num_columns = 4\n",
    "\n",
    "with open(file_path) as input_file:\n",
    "    newLines = []\n",
    "    for line in input_file:\n",
    "        newLine = [x.replace('\"', '').strip() for x in line.split(separator)]\n",
    "        if len(newLine) == num_columns:\n",
    "            newLines.append(newLine)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.to_csv(new_file_path, sep = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(newLines))\n",
    "print (newLines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print (os.path.exists(new_file_path))\n",
    "if os.path.exists(new_file_path):    \n",
    "    print (\"[*] Removing old file...\")\n",
    "    os.remove(new_file_path);\n",
    "    print (\"[+] Old file removed.\")\n",
    "    \n",
    "print (os.path.exists(new_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cols = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "# for x in np.arange(1, 101, 1):\n",
    "#     cols.append('item_' + str(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (os.path.exists(new_file_path))\n",
    "fout = open(new_file_path,'a');\n",
    "print (fout)\n",
    "fout.write('\\t'.join(cols)+'\\n')\n",
    "for index, newLine in enumerate(newLines):\n",
    "    line = '\\t'.join(newLines[index])+'\\n'\n",
    "    fout.write(line);\n",
    "    \n",
    "print (line)\n",
    "fout.close()\n",
    "print (os.path.exists(new_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (os.path.exists(new_file_path))\n",
    "fout = open(new_file_path,'w');\n",
    "print (fout)\n",
    "fout.write('user_id\\titem_id\\trating\\t\\n')\n",
    "for newLine in newLines:\n",
    "    line = str(newLine[0])+'\\t'+str(newLine[1])+'\\t'+str(newLine[2]).replace('\"', '') +'\\n'\n",
    "    fout.write(line);\n",
    "    \n",
    "print (line)\n",
    "fout.close()\n",
    "print (os.path.exists(new_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (os.path.exists(new_file_path))\n",
    "fout = open(new_file_path,'w');\n",
    "print (fout)\n",
    "fout.write('user_id\\titem_id\\trating\\ttimestamp\\n')\n",
    "for newLine in newLines:\n",
    "    line = str(newLine[0])+'\\t'+str(newLine[1])+'\\t'+str(newLine[2])+'\\t'+str(newLine[3])+'\\n'\n",
    "    fout.write(line);\n",
    "    \n",
    "print (line)\n",
    "fout.close()\n",
    "print (os.path.exists(new_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (os.path.exists(new_file_path))\n",
    "\n",
    "fin = open(new_file_path,'r');\n",
    "print (fin.readline())\n",
    "print (fin.readline())\n",
    "print (fin.readline())\n",
    "print (fin.readline())\n",
    "print (fin.readline())\n",
    "fin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# dataset = 'MovieLens'\n",
    "# dataset_type = '1M'\n",
    "dataset = 'Jester'\n",
    "dataset_type = 'jester'\n",
    "\n",
    "folder = \"../Datasets/\" + dataset + \"/\" + dataset_type + \"/\"\n",
    "filepath = \"{}ratings.csv\".format(folder)\n",
    "output_folder = '../Datasets/' + dataset + '/' + dataset_type + '/outputs/'\n",
    "dataset_output_folder = output_folder + 'sparsity_dataset/'\n",
    "\n",
    "# Visualize file content\n",
    "# df_whole = pd.read_csv(filepath, sep='\\t', header=0, names=['user_id', 'item_id', 'rating', 'timestamp']) \n",
    "df_whole = pd.read_csv(filepath, sep='\\t', header=None) \n",
    "df_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole.drop([0], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whole.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "\n",
    "# update_progress() : Displays or updates a console progress bar\n",
    "## Accepts a float between 0 and 1. Any int will be converted to a float.\n",
    "## A value under 0 represents a 'halt'.\n",
    "## A value at 1 or bigger represents 100%\n",
    "def update_progress(progress):\n",
    "    barLength = 10 # Modify this to change the length of the progress bar\n",
    "    status = \"\"\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "        status = \"error: progress var must be float\\r\\n\"\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "        status = \"Halt...\\r\\n\"\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "        status = \"Done...\\r\\n\"\n",
    "    block = int(round(barLength*progress))\n",
    "    text = \"\\rPercent: [{0}] {1:.2f}% {2}\".format( \"#\"*block + \"-\"*(barLength-block), progress*100, status)\n",
    "    sys.stdout.write(text)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_index/float(df_whole.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "items_ids = np.array([])\n",
    "users_ids = np.array([])\n",
    "ratings = np.array([])\n",
    "\n",
    "for user_index in df_whole.index:\n",
    "\n",
    "    update_progress(user_index/float(df_whole.shape[0]))\n",
    "    \n",
    "    row = np.array(df_whole.iloc[user_index])\n",
    "    row = np.array([float(str(x).replace(',', '.')) for x in row])\n",
    "    index = np.where(row < 99)\n",
    "\n",
    "    temp_items_ids = np.array([x + 1 for x in index])\n",
    "    temp_ratings = row[index]\n",
    "    temp_users_ids = np.repeat(user_index, len(temp_ratings))\n",
    "\n",
    "    items_ids = np.append(items_ids, temp_items_ids)\n",
    "    users_ids = np.append(users_ids, temp_users_ids)\n",
    "    ratings = np.append(ratings, temp_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.DataFrame(columns = ['user_id', 'item_id', 'rating'])\n",
    "df_ratings['user_id'] = users_ids\n",
    "df_ratings['item_id'] = items_ids\n",
    "df_ratings['rating'] = ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings.to_csv(new_file_path, sep = '\\t', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ids = np.array([])\n",
    "items_ids = np.append(items_ids, [2, 3, 4])\n",
    "items_ids = np.append(items_ids, [2, 3, 4])\n",
    "items_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
